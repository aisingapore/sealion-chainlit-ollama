# Set the base URL of the Ollama API
LLM_BASE_URL=http://localhost:11434/v1

# Use the following URL if the app is launched with Docker Compose
# LLM_BASE_URL=http://ollama:11434/v1

# Set the model name
LLM_MODEL=aisingapore/gemma2-9b-cpt-sea-lionv3-instruct:q4_0

# Set the randomness of the modelâ€™s outputs during text generation
LLM_TEMPERATURE=0.8